"""
zeus_chat.py - è»å¸«Zeus ãƒãƒ£ãƒƒãƒˆãƒ­ã‚¸ãƒƒã‚¯

ãƒã‚¹ã‚¿ãƒ‡ãƒ¼ã‚¿ã¨åœ¨åº«çŠ¶æ³ã‚’ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦Gemini APIã«æ¸¡ã—ã€
ã€Œã‚¢ãƒˆãƒ©ã‚¹å·¥æˆ¿ã®è»å¸«Zeusã€ã¨ã—ã¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«å›ç­”ã™ã‚‹ã€‚

Uses: google-genai (æ–°SDK)
"""

import json
import logging
import os
try:
    from google import genai
    from google.genai import types
except ImportError:
    genai = None
    types = None
    logging.warning("google-genai library not found. Chat features will be disabled, but search logic is available.")
import pandas as pd

OUTPUT_VERSION = "2026-02-15 v2 (Detailed Process Times)"

logger = logging.getLogger(__name__)

DATA_DIR = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'data')
HISTORY_PATH = os.path.join(DATA_DIR, 'history_summary.json')

def load_event_master():
    """Zeusç›£è¦–ç”¨ã®ã‚¤ãƒ™ãƒ³ãƒˆãƒã‚¹ã‚¿ã‚’èª­ã¿è¾¼ã‚€"""
    event_path = os.path.join(DATA_DIR, 'event_master.json')
    if not os.path.exists(event_path):
        return []
    try:
        with open(event_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        logger.error(f"Event master load error: {e}")
        return []


def load_history_stats():
    """
    ã€æœ€çµ‚ä»•æ§˜ã€‘èµ·ç‚¹æ—¥ã‚’ type:"initial" ã‹ã‚‰å‹•çš„å–å¾—ã—ã€å…¨ãƒ­ã‚°é€šç®—ã®ãƒšãƒ¼ã‚¹ã‚’ç®—å‡ºã€‚
    
    ä»•æ§˜:
      èµ·ç‚¹ = history_summary.json å†…ã® type:"initial" ãƒ¬ã‚³ãƒ¼ãƒ‰ã® date
      ãƒšãƒ¼ã‚¹ = (æœ€æ–°total_current - initial.total_current) / (ä»Šæ—¥ - èµ·ç‚¹æ—¥)
    
    Returns:
        dict: {pace, last_count, last_date, is_long_term,
               origin_date, origin_count, origin_details} or None
    """
    if not os.path.exists(HISTORY_PATH):
        return None
    
    try:
        with open(HISTORY_PATH, 'r', encoding='utf-8') as f:
            history = json.load(f)
            
        if not history:
            return None

        from datetime import datetime

        # â˜… ä»•æ§˜: type="initial" ã‹ã‚‰èµ·ç‚¹ãƒ‡ãƒ¼ã‚¿ã‚’å‹•çš„å–å¾—ï¼ˆãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å³ç¦ï¼‰
        initial_entry = None
        for h in history:
            if h.get('type') == 'initial':
                initial_entry = h
                break
        
        if not initial_entry:
            # initial ãŒç„¡ã„å ´åˆã€æœ€å¤ã®ã‚¨ãƒ³ãƒˆãƒªã‚’ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã¨ã™ã‚‹
            logger.warning("type='initial' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚æœ€å¤ã®ã‚¨ãƒ³ãƒˆãƒªã‚’èµ·ç‚¹ã¨ã—ã¾ã™ã€‚")
            initial_entry = history[0]

        # èµ·ç‚¹æ—¥ã®ãƒ‘ãƒ¼ã‚¹
        origin_ts = initial_entry.get('timestamp') or initial_entry.get('date')
        if not origin_ts:
            return None
        try:
            origin_dt = datetime.fromisoformat(origin_ts.replace('Z', '+00:00'))
        except Exception:
            return None
        
        origin_count = initial_entry.get('total_current', 0)
        origin_details = initial_entry.get('details', {})

        # å…¨ã‚¨ãƒ³ãƒˆãƒªã« _dt ã‚’ä»˜ä¸
        for h in history:
            ts = h.get('timestamp') or h.get('date')
            if not ts:
                continue
            try:
                h['_dt'] = datetime.fromisoformat(ts.replace('Z', '+00:00'))
            except Exception:
                continue

        valid = [h for h in history if '_dt' in h]
        if len(valid) < 2:
            return None
            
        valid.sort(key=lambda x: x['_dt'])
        current = valid[-1]

        # â˜… ä»•æ§˜: (æœ€æ–°total_current - initial.total_current) / (ä»Šæ—¥ - èµ·ç‚¹æ—¥)
        now = datetime.now(origin_dt.tzinfo)  # ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³ä¸€è‡´
        total_days = (now - origin_dt).days
        if total_days <= 0:
            total_days = 1
        
        total_produced = current.get('total_current', 0) - origin_count
        pace_per_day = total_produced / total_days
        
        # ç›´è¿‘2ç‚¹é–“ã®ãƒšãƒ¼ã‚¹ï¼ˆå‚è€ƒå€¤ï¼‰
        is_long_term = False
        if len(valid) >= 2:
            prev = valid[-2]
            recent_days = (current['_dt'] - prev['_dt']).days
            if recent_days <= 0:
                recent_days = 1
            recent_diff = current.get('total_current', 0) - prev.get('total_current', 0)
            recent_pace = recent_diff / recent_days
            
            if 0 < recent_pace <= 10:
                pace_per_day = recent_pace
            else:
                is_long_term = True

        return {
            "pace": round(pace_per_day, 2),
            "last_count": current.get('total_current', 0),
            "last_date": current['_dt'].strftime('%Y-%m-%d'),
            "is_long_term": is_long_term,
            # â˜… èµ·ç‚¹æƒ…å ±ã‚‚è¿”ã™ï¼ˆbuild_system_prompt ã§ä½¿ç”¨ï¼‰
            "origin_date": origin_dt.strftime('%Y-%m-%d'),
            "origin_count": origin_count,
            "origin_details": origin_details,
        }

    except Exception as e:
        logger.error(f"å±¥æ­´çµ±è¨ˆã®è¨ˆç®—å¤±æ•—: {e}")
        return None


def get_daily_achievements():
    """æœ¬æ—¥ã®æˆæœï¼ˆåœ¨åº«å¢—åˆ†ï¼‰ã‚’è¨ˆç®—ã—ã¦æ–‡å­—åˆ—ã§è¿”ã™"""
    try:
        import json
        import os
        from datetime import datetime, timedelta

        # history_path check (uses global constant)
        if not os.path.exists(HISTORY_PATH):
            return "â˜…æœ¬æ—¥ã®æˆæœ: ï¼ˆå±¥æ­´ãƒ‡ãƒ¼ã‚¿ãªã—ï¼‰"

        with open(HISTORY_PATH, 'r', encoding='utf-8') as f:
            history = json.load(f)

        if not history:
            return "â˜…æœ¬æ—¥ã®æˆæœ: ï¼ˆå±¥æ­´ãƒ‡ãƒ¼ã‚¿ãªã—ï¼‰"

        # æ—¥ä»˜é †ã«ã‚½ãƒ¼ãƒˆ
        parsed_history = []
        for h in history:
            ts_str = h.get('timestamp') or h.get('date', '')
            if not ts_str: continue
            try:
                # ISOãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå¯¾å¿œ (Zé™¤å»)
                dt = datetime.fromisoformat(ts_str.replace('Z', '+00:00'))
                h['_dt'] = dt
                parsed_history.append(h)
            except:
                continue
        
        parsed_history.sort(key=lambda x: x['_dt'])

        if not parsed_history:
            return "â˜…æœ¬æ—¥ã®æˆæœ: ï¼ˆæœ‰åŠ¹ãªå±¥æ­´ãªã—ï¼‰"

        # â˜… details ãŒç©ºã§ãªã„ãƒ­ã‚°ã®ã¿æœ‰åŠ¹ã¨ã™ã‚‹ï¼ˆå¤ã„å½¢å¼ã®ã‚¨ãƒ³ãƒˆãƒªã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼‰
        valid_history = [h for h in parsed_history if h.get('details') and len(h.get('details', {})) > 0]
        
        if len(valid_history) < 2:
            return "â˜…æœ¬æ—¥ã®æˆæœ: ï¼ˆæ¯”è¼ƒç”¨ã®è©³ç´°ãƒ‡ãƒ¼ã‚¿ä¸è¶³ - detailsä»˜ãã‚¨ãƒ³ãƒˆãƒªãŒ2ä»¶ä»¥ä¸Šå¿…è¦ï¼‰"

        # â˜… ä»•æ§˜: æœ€æ–°ã®ãƒ­ã‚°ã‚’ã€Œç¾åœ¨ã®çŠ¶æ…‹ã€ã¨ã™ã‚‹
        latest = valid_history[-1]
        latest_date = latest['_dt'].date()
        
        # æ¯”è¼ƒå¯¾è±¡ï¼ˆæ˜¨æ—¥ä»¥å‰ã®æœ€å¾Œã®ãƒ­ã‚°ï¼‰ã‚’æ¢ã™
        base_entry = None
        for h in reversed(valid_history[:-1]):
            if h['_dt'].date() < latest_date:
                base_entry = h
                break
        
        # ã‚‚ã—æ˜¨æ—¥ä»¥å‰ã®ãƒ­ã‚°ãŒãªã‘ã‚Œã°ã€è¨˜éŒ²ä¸Šã®æœ€åˆã®ãƒ­ã‚°ã‚’åŸºæº–ã«ã™ã‚‹
        if not base_entry:
            base_entry = valid_history[0]
            
        latest_details = latest.get('details', {})
        base_details = base_entry.get('details', {})

        # å·®åˆ†è¨ˆç®—
        achievements = []
        
        # ãƒã‚¹ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¦åå‰è§£æ±º
        master_map = {}
        try:
            master_path = os.path.join(DATA_DIR, 'production_master.json')
            if os.path.exists(master_path):
                with open(master_path, 'r', encoding='utf-8') as f:
                    m_data = json.load(f)
                    for m in m_data:
                        mid = str(m.get('id', '')).strip()
                        if mid:
                            master_map[mid] = {
                                'name': m.get('name', mid),
                                'part': m.get('part', '')
                            }
        except:
            pass
        
        # æœ€æ–°ã«ã‚ã‚‹IDã‚’èµ°æŸ»
        for item_id, info in latest_details.items():
            # infoã¯ {"count": 10, ...} å½¢å¼ã¾ãŸã¯æ•°å€¤
            current_count = 0
            if isinstance(info, dict):
                current_count = info.get('count', 0)
            elif isinstance(info, (int, float, str)):
                 try: current_count = int(info)
                 except: pass

            # æ¯”è¼ƒå¯¾è±¡
            base_info = base_details.get(item_id, {})
            base_count = 0
            if isinstance(base_info, dict):
                base_count = base_info.get('count', 0)
            elif isinstance(base_info, (int, float, str)):
                 try: base_count = int(base_info)
                 except: pass
            
            diff = current_count - base_count
            
            # å¢—åŠ åˆ†ã®ã¿å ±å‘Š
            if diff > 0:
                item_info = master_map.get(item_id, {})
                if isinstance(item_info, dict):
                    name = item_info.get('name', item_id)
                    part = item_info.get('part', '')
                    display_name = f"{name} ({part})" if part else name
                else:
                    display_name = str(item_info)
                achievements.append(f"{display_name} +{diff}")
        
        if not achievements:
            return "â˜…æœ¬æ—¥ã®æˆæœ: ãªã—ï¼ˆä»Šã®ã¨ã“ã‚åœ¨åº«ã®å¢—åŠ ã¯ã‚ã‚Šã¾ã›ã‚“ï¼‰"
            
        return "â˜…æœ¬æ—¥ã®æˆæœ: " + " / ".join(achievements) + "ï¼ï¼"

    except Exception as e:
        logger.error(f"æˆæœè¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
        return f"â˜…æœ¬æ—¥ã®æˆæœ: (è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e})"


def build_system_prompt(master_data: list, inventory_df: pd.DataFrame = None, current_event_name: str = None, all_event_names: list = None, user_message: str = None) -> str:
    """
    ãƒã‚¹ã‚¿ãƒ‡ãƒ¼ã‚¿ã¨åœ¨åº«çŠ¶æ³ã‹ã‚‰ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰ã™ã‚‹ã€‚

    Args:
        master_data: load_master_json() ã®å‡ºåŠ›ï¼ˆå•†å“ãƒªã‚¹ãƒˆï¼‰
        inventory_df: calculate_inventory() ã®å‡ºåŠ›ï¼ˆåœ¨åº«DataFrameï¼‰
        current_event_name: ç¾åœ¨é¸æŠä¸­ã®ã‚¤ãƒ™ãƒ³ãƒˆã‚·ãƒ¼ãƒˆåï¼ˆä¾‹: "ã‚¯ãƒªãƒ2605"ï¼‰
        all_event_names: å…¨ã‚¤ãƒ™ãƒ³ãƒˆã‚·ãƒ¼ãƒˆåã®ãƒªã‚¹ãƒˆï¼ˆä¾‹: ["ã‚¯ãƒªãƒ2605", "ãƒ‡ã‚¶ãƒ•ã‚§ã‚¹58"]ï¼‰

    Returns:
        str: ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ–‡å­—åˆ—
    """
    
    # --- å•†å“ãƒã‚¹ã‚¿ã®è¦ç´„ãƒ†ã‚­ã‚¹ãƒˆ & æ®‹ä½œæ¥­æ™‚é–“ã®è¨ˆç®— ---
    product_lines = []
    
    total_remaining_count = 0
    total_target_count = 0
    
    # æ™‚é–“è¨ˆç®—ç”¨
    total_nc_min = 0
    total_manual_min = 0
    
    if master_data:
        for item in master_data:
            nc = item.get("process", {}).get("nc", {})
            nc_unit = (
                nc.get("front_rough_min", 0)
                + nc.get("front_finish_min", 0)
                + nc.get("back_rough_min", 0)
                + nc.get("back_finish_min", 0)
            )
            prep = item.get("process", {}).get("prep", {})
            assembly = item.get("process", {}).get("assembly", {})
            manual = item.get("process", {}).get("manual", {})

            manual_unit = (
                prep.get("unit_min", 0) # setupã¯ç„¡è¦–
                + assembly.get("cut_off_min", 0)
                + assembly.get("bonding_min", 0)
                + manual.get("fitting_min", 0)
                + manual.get("machine_work_min", 0)
                + manual.get("sanding_min", 0)
                + manual.get("assembly_min", 0)
            )
            all_unit = nc_unit + manual_unit # ä¹¾ç‡¥é™¤ã

            reqs = item.get("requirements", {})
            
            # --- æ®‹æ•°é›†è¨ˆ ---
            tgt = item.get('target_quantity', 0)
            rem = item.get('remaining', 0)
            total_target_count += tgt
            total_remaining_count += rem
            
            # --- æ®‹æ™‚é–“é›†è¨ˆ ---
            # ä¸è¶³æ•° * å˜ä¾¡æ™‚é–“
            if rem > 0:
                total_nc_min += rem * nc_unit
                total_manual_min += rem * manual_unit

            # --- ã‚¤ãƒ™ãƒ³ãƒˆæƒ…å ±ã®å‹•çš„æ³¨å…¥ ---
            event_data = item.get('event_data', {})
            event_info_str = ""
            
            if event_data:
                details = []
                for k, v in event_data.items():
                    details.append(f"{k}: {v}")
                
                if rem > 0:
                     details.append(f"æ®‹æ•°: {rem}")

                if details:
                    event_info_str = f"   â˜…ã‚¤ãƒ™ãƒ³ãƒˆæƒ…å ±: [{', '.join(details)}]"

            line = (
                f"- **{item.get('name', '?')}** ({item.get('part', '?')}) "
                f"[ã‚«ãƒ†ã‚´ãƒª: {item.get('category', '?')}]\n"
                f"  ID: {item.get('id', '?')} / å˜ä¾¡: Â¥{item.get('price', 0):,} / "
                f"ãƒã‚¹ã‚¿åœ¨åº«: {item.get('current_stock', 0)} {event_info_str}\n"
                f"  ææ–™: {reqs.get('material_type', '?')} / "
                f"NCãƒã‚·ãƒ³: {reqs.get('nc_machine_type', '?')} / "
                f"å–æ•°: {reqs.get('yield', 1)}\n"
                f"  ã€å·¥ç¨‹æ™‚é–“(åˆ†)ã€‘\n"
                f"    ç”Ÿåœ°å˜ä½“{prep.get('unit_min', 0)} / "
                f"    NCåˆè¨ˆ: {nc_unit}åˆ† (è¡¨ç²—:{nc.get('front_rough_min', 0)} / è¡¨ä»•:{nc.get('front_finish_min', 0)} / è£ç²—:{nc.get('back_rough_min', 0)} / è£ä»•:{nc.get('back_finish_min', 0)})\n"
                f"    çµ„ä»˜åˆè¨ˆ: {assembly.get('cut_off_min', 0)+assembly.get('bonding_min', 0)} "
                f"(åˆ‡æ–­:{assembly.get('cut_off_min', 0)} / æ¥ç€:{assembly.get('bonding_min', 0)}) / "
                f"    æ‰‹åŠ å·¥åˆè¨ˆ: {manual_unit - (prep.get('unit_min',0)+assembly.get('cut_off_min',0)+assembly.get('bonding_min',0))} "
                f"(æº–å‚™:{prep.get('unit_min', 0)} / åµŒåˆ:{manual.get('fitting_min', 0)} / æ©Ÿæ¢°:{manual.get('machine_work_min', 0)} / ç ”ç£¨:{manual.get('sanding_min', 0)} / çµ„ç«‹:{manual.get('assembly_min', 0)}) \n"
                f"  â± å…¨å·¥ç¨‹åˆè¨ˆ(ä¹¾ç‡¥é™¤ã): {all_unit}åˆ†"
            )
            product_lines.append(line)

    product_context = "\n".join(product_lines) if product_lines else "ï¼ˆãƒã‚¹ã‚¿ãƒ‡ãƒ¼ã‚¿ãªã—ï¼‰"
    
    # åˆè¨ˆæ™‚é–“ (æ™‚é–“å˜ä½)
    total_remaining_hours = (total_nc_min + total_manual_min) / 60
    
    # ãƒ—ãƒªãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆSyntaxErrorå›é¿ã®ãŸã‚ï¼‰
    nc_str = f"{total_nc_min / 60:.1f}"
    manual_str = f"{total_manual_min / 60:.1f}"
    
    # è¤‡é›‘ãªF-stringã‚’å›é¿ã™ã‚‹ãŸã‚ã«å¤–ã§å®šç¾©
    time_info_line = f"- **æ®‹ã‚Šç·ä½œæ¥­æ™‚é–“: {total_remaining_hours:.1f} æ™‚é–“** (NC: {nc_str}h / æ‰‹: {manual_str}h)"

    # --- ãƒã‚¹ã‚¿æ¤œç´¢ç”¨ãƒãƒƒãƒ—ä½œæˆ (ID -> Item) ---
    master_map = {str(item.get('id', '')): item for item in master_data if item.get('id')}

    # --- åœ¨åº«çŠ¶æ³ã®è¦ç´„ãƒ†ã‚­ã‚¹ãƒˆ ---
    inventory_context = "ï¼ˆåœ¨åº«ãƒ‡ãƒ¼ã‚¿ãªã—ï¼‰"
    if inventory_df is not None and not inventory_df.empty:
        inv_lines = []
        for _, row in inventory_df.iterrows():
            name = row.get("å•†å“å", "?")
            part_val = row.get("éƒ¨ä½", "?") # Using 'éƒ¨ä½' for consistency check if needed, or row key
            # inventory_df is from calculate_inventory, which likely has 'ID' or 'id'.
            # Let's check inventory.py -> It preserves ID if master has it.
            # Assuming row has an identifier or we match by Name/Part.
            # Actually, `inventory_df` usually has the same index or columns as master DF if merged.
            # But let's look at `calculate_inventory` return. It returns a DF with "å•†å“å", "éƒ¨ä½", "ID" etc.
            
            # Try to find matching master item to get process times
            # Prefer ID match
            row_id = str(row.get('ID', '')).strip()
            master_item = master_map.get(row_id)
            
            # Fallback: Name match (less reliable but okay for now)
            if not master_item:
                # simple name search
                pass 

            nc_ts = 0
            man_ts = 0
            
            if master_item:
                # Calculate times
                proc = master_item.get('process', {})
                n = proc.get('nc', {})
                nc_ts = (n.get('front_rough_min', 0) + n.get('front_finish_min', 0) + 
                         n.get('back_rough_min', 0) + n.get('back_finish_min', 0))
                
                p = proc.get('prep', {})
                a = proc.get('assembly', {})
                m = proc.get('manual', {})
                man_ts = (p.get('unit_min', 0) + a.get('cut_off_min', 0) + a.get('bonding_min', 0) +
                          m.get('fitting_min', 0) + m.get('machine_work_min', 0) + m.get('sanding_min', 0) + m.get('assembly_min', 0))

            body = row.get("æœ¬ä½“", 0)
            sheath = row.get("é˜", 0)
            status = row.get("status_text", "?")
            confirmed = row.get("ç¢ºå®šæ•°", 0)
            sales = row.get("è²©å£²æ•°", 0)
            
            inv_lines.append(
                f"- {name}: æœ¬ä½“={body}, é˜={sheath}, "
                f"ç¢ºå®šæ•°={confirmed}, è²©å£²æ•°={sales}, ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹={status} "
                f"[NC: {nc_ts}åˆ† / æ‰‹: {man_ts}åˆ†]"
            )
        inventory_context = "\n".join(inv_lines)
    # ================================================================
    # â˜… ä»•æ§˜æ›¸æº–æ‹ : Pythonå´ã§å…¨è¨ˆç®—ã‚’ç¢ºå®šã—ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«æ³¨å…¥
    # ================================================================
    from datetime import datetime, timedelta
    now = datetime.now()
    today_str = now.strftime('%Y/%m/%d')
    
    # --- A. èµ·ç‚¹æ—¥ã®å‹•çš„å–å¾— (ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å³ç¦) ---
    stats = load_history_stats()
    daily_pace = stats['pace'] if stats else 0
    is_long_term = stats.get('is_long_term', False) if stats else False
    origin_date_str = stats.get('origin_date', 'ä¸æ˜') if stats else 'ä¸æ˜'
    origin_count = stats.get('origin_count', 0) if stats else 0
    
    # --- B. IDã«ã‚ˆã‚‹ç²¾å¯†ãƒãƒ¼ã‚¸ (production_master Ã— history initial) ---
    # load_history_stats() ãŒè¿”ã™ origin_details ã‚’åˆ©ç”¨
    origin_details = stats.get('origin_details', {}) if stats else {}
    
    merge_lines = []
    for item in (master_data or []):
        item_id = str(item.get('id', '')).strip()
        if not item_id:
            continue
        target = item.get('target_quantity', 0)
        current = item.get('current_stock', 0)
        
        # èµ·ç‚¹åœ¨åº« (IDãƒ™ãƒ¼ã‚¹ã§ãƒãƒ¼ã‚¸)
        init_info = origin_details.get(item_id, {})
        init_count = init_info.get('count', 0) if isinstance(init_info, dict) else 0
        
        produced = current - init_count  # èµ·ç‚¹ã‹ã‚‰ã®ç”Ÿç”£æ•°
        remaining = max(0, target - current)
        
        merge_lines.append(
            f"  {item.get('name', '?')} ({item.get('part', '?')}): "
            f"ID={item_id}, èµ·ç‚¹åœ¨åº«={init_count}, ç¾åœ¨={current}, "
            f"ç›®æ¨™={target}, ç”Ÿç”£æ•°={produced}, æ®‹={remaining}"
        )
    
    merge_context = "\n".join(merge_lines) if merge_lines else "ï¼ˆãƒãƒ¼ã‚¸ãƒ‡ãƒ¼ã‚¿ãªã—ï¼‰"
    
    # --- C. ä¸è¶³å·¥æ•°ã®ç²¾å¯†ç®—å‡º (PythonãŒå®Œé‚) ---
    # total_nc_min, total_manual_min, total_remaining_count ã¯æ—¢ã«L230-L310ã§è¨ˆç®—æ¸ˆã¿
    
    # --- D. æœªæ¥äºˆæ¸¬ (å·¥ç¨‹æ™‚é–“ãƒ™ãƒ¼ã‚¹) ---
    prediction_msg = "ãƒ‡ãƒ¼ã‚¿ä¸è¶³ã®ãŸã‚äºˆæ¸¬ä¸èƒ½"
    reality_check_msg = ""
    DAILY_WORK_HOURS = 8.0
    
    if daily_pace > 0 and total_remaining_count > 0:
        avg_hours_per_item = total_remaining_hours / total_remaining_count if total_remaining_count > 0 else 0
        
        days_needed_by_pace = total_remaining_count / daily_pace
        days_needed_by_hours = total_remaining_hours / DAILY_WORK_HOURS if DAILY_WORK_HOURS > 0 else float('inf')
        
        days_needed = max(days_needed_by_pace, days_needed_by_hours)
        finish_date = now + timedelta(days=days_needed)
        
        estimated_daily_hours = daily_pace * avg_hours_per_item
        
        pace_type_str = "é•·æœŸå¹³å‡" if is_long_term else "ç›´è¿‘å®Ÿç¸¾"
        prefix_msg = f"ï¼ˆ{pace_type_str}ãƒ™ãƒ¼ã‚¹ï¼‰" if is_long_term else ""
        
        # â˜… æœŸé™ã‚‚å‹•çš„ã«ï¼ˆã‚¤ãƒ™ãƒ³ãƒˆãƒã‚¹ã‚¿ã®ã‚¢ã‚¯ãƒ†ã‚£ãƒ–æœ€é æœŸé™ã‚’å–å¾—å¯èƒ½ã ãŒã€ã“ã“ã§ã¯ä¿å®ˆçš„ã«å›ºå®šï¼‰
        # å°†æ¥çš„ã«ã¯ã‚¤ãƒ™ãƒ³ãƒˆãƒã‚¹ã‚¿ã‹ã‚‰å‹•çš„ã«å–å¾—ã™ã¹ã
        # æš«å®š: ã‚¤ãƒ™ãƒ³ãƒˆãƒã‚¹ã‚¿ã«ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚¤ãƒ™ãƒ³ãƒˆãŒã‚ã‚Œã°ãã®é–‹å‚¬æ—¥ã‚’æœŸé™ã«ã™ã‚‹
        event_master = load_event_master()
        deadline = None
        deadline_event_name = ""
        if event_master:
            for evt in event_master:
                if evt.get('is_active', False):
                    date_str = evt.get('date', '')
                    if date_str:
                        try:
                            d_str = str(date_str).replace('/', '-').split(' ')[0]
                            deadline = datetime.strptime(d_str, '%Y-%m-%d')
                            deadline_event_name = evt.get('name', '?')
                            break
                        except ValueError:
                            pass
        
        if not deadline:
            deadline = datetime(2026, 5, 5)  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            deadline_event_name = "æœ€çµ‚æœŸé™"

        remaining_days_to_deadline = (deadline - now).days

        if finish_date <= deadline:
            prediction_msg = f"{prefix_msg}ç¾åœ¨ã®ãƒšãƒ¼ã‚¹({daily_pace:.1f}å€‹/æ—¥)ãªã‚‰ {finish_date.strftime('%Y-%m-%d')} ã«å®Œäº†äºˆå®šã€‚{deadline_event_name}({deadline.strftime('%Y-%m-%d')})ã¾ã§{remaining_days_to_deadline}æ—¥ã‚ã‚Šã€é–“ã«åˆã†è¦‹è¾¼ã¿ã€‚"
        else:
            overshoot_days = (finish_date - deadline).days
            prediction_msg = f"{prefix_msg}ç¾åœ¨ã®ãƒšãƒ¼ã‚¹({daily_pace:.1f}å€‹/æ—¥)ã ã¨ {finish_date.strftime('%Y-%m-%d')} å®Œäº†äºˆå®šã§ã€{deadline_event_name}({deadline.strftime('%Y-%m-%d')})ã‚ˆã‚Š{overshoot_days}æ—¥è¶…é..."
        
        if estimated_daily_hours > 12.0:
            reality_check_msg = f"âš ï¸ è­¦å‘Š: ç¾åœ¨ã®æ—¥ç”£ãƒšãƒ¼ã‚¹({daily_pace:.1f}å€‹)ã‚’ç¶­æŒã™ã‚‹ã«ã¯ã€1æ—¥ç´„{estimated_daily_hours:.1f}æ™‚é–“ã®ä½œæ¥­ãŒå¿…è¦ã€‚ç„¡ç†ã¯ç¦ç‰©ã§ã™ã€‚"

    elif total_remaining_count <= 0:
        prediction_msg = "å…¨ç›®æ¨™é”æˆæ¸ˆã¿ï¼å‹åˆ©ã ï¼"
    elif daily_pace <= 0:
        prediction_msg = "ç”Ÿç”£ãƒšãƒ¼ã‚¹ãŒè¨ˆæ¸¬ã§ããªã„ãŸã‚äºˆæ¸¬ä¸èƒ½ï¼ˆã¾ãšã¯ä½œæ¥­ã‚’é–‹å§‹ã—ã€ãƒ‡ãƒ¼ã‚¿ã‚’è“„ç©ã›ã‚ˆï¼‰"

    # --- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®é–¢å¿ƒäº‹é …ï¼ˆæ¤œç´¢ãƒ»åˆç®—ãƒ­ã‚¸ãƒƒã‚¯ï¼‰ ---
    search_context = ""
    if user_message:
        found_items = search_products_by_query(master_data, user_message)
        if found_items:
            search_context = build_search_context(found_items)
            print(f"--- [Zeus Search] Found {len(found_items)} items for query ---")

    # --- æœ¬æ—¥ã®æˆæœ ---
    achievements_str = get_daily_achievements()

    # --- â˜… ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ç©ºãæ™‚é–“ & Google Tasks ã®èª­ã¿è¾¼ã¿ ---
    calendar_context = ""
    tasks_context = ""
    cal_data_path = os.path.join(DATA_DIR, 'atlas_integrated_data.json')
    if os.path.exists(cal_data_path):
        try:
            with open(cal_data_path, 'r', encoding='utf-8') as f:
                cal_data = json.load(f)
            
            # ç›´è¿‘1é€±é–“ã®æ—¥åˆ¥ç©ºãæ™‚é–“ã‚’æŠ½å‡º
            daily_schedule = cal_data.get('daily_schedule', [])
            if daily_schedule:
                today_date = now.strftime('%Y-%m-%d')
                week_slots = []
                for slot in daily_schedule[:7]:  # ç›´è¿‘7æ—¥åˆ†
                    d = slot.get('date', '')
                    if d < today_date:
                        continue
                    dow = slot.get('day_of_week', '?')
                    free_h = slot.get('total_free_hours', 0)
                    blocked = slot.get('is_blocked', False)
                    blocks = slot.get('free_blocks', [])
                    
                    if blocked:
                        week_slots.append(f"  {d}({dow}): â– çµ‚æ—¥ãƒ–ãƒ­ãƒƒã‚¯ï¼ˆäºˆå®šã‚ã‚Šï¼‰")
                    else:
                        block_str = ', '.join([f"{b['start']}-{b['end']}({b['hours']}h)" for b in blocks[:4]])
                        week_slots.append(f"  {d}({dow}): ç©ºã{free_h}h [{block_str}]")
                
                if week_slots:
                    calendar_context = "\n".join(week_slots)
            
            # Google Tasksï¼ˆæœŸæ—¥ä»˜ãï¼‰
            google_tasks = cal_data.get('google_tasks', [])
            if google_tasks:
                task_lines = []
                for t in google_tasks[:10]:
                    days_until = t.get('days_until')
                    urgency = 'ğŸš¨' if days_until is not None and days_until <= 3 else 'ğŸ“‹'
                    days_label = f"ã‚ã¨{days_until}æ—¥" if days_until is not None else 'æœŸæ—¥ä¸æ˜'
                    task_lines.append(f"  {urgency} {t['title']} â€” æœŸæ—¥: {t.get('due_date', '?')} ({days_label})")
                tasks_context = "\n".join(task_lines)
        except Exception as e:
            logger.error(f"ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

    # --- â˜… event_master.json ã‚’ Raw JSON ã¨ã—ã¦æµã—è¾¼ã¿ï¼ˆåŠ å·¥ç¦æ­¢ï¼‰ ---
    if not event_master:
        event_master = load_event_master()
    
    event_raw_json = "ï¼ˆevent_master.json ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼‰"
    if event_master:
        try:
            event_raw_json = json.dumps(event_master, ensure_ascii=False, indent=2)
        except Exception:
            event_raw_json = str(event_master)

    # ================================================================
    # â˜… System Prompt Construction (ä»•æ§˜æ›¸: æ—¥ä»˜â†’ç¢ºå®šã‚µãƒãƒªãƒ¼â†’Rawç”Ÿãƒ‡ãƒ¼ã‚¿)
    # ================================================================
    system_prompt = f"""
## æœ€é‡è¦: æ—¥ä»˜æƒ…å ±
- æœ¬æ—¥ã®æ—¥ä»˜: {today_str}
- ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆèµ·ç‚¹æ—¥: {origin_date_str}
- èµ·ç‚¹ã‹ã‚‰ã®çµŒéæ—¥æ•°: {(now - datetime.strptime(origin_date_str, '%Y-%m-%d')).days if origin_date_str != 'ä¸æ˜' else 'ä¸æ˜'}æ—¥

## Pythonè¨ˆç®—æ¸ˆã¿ç¢ºå®šã‚µãƒãƒªãƒ¼ï¼ˆAIã¯ã“ã®æ•°å€¤ã‚’ä¿¡é ¼ã›ã‚ˆã€‚è‡ªåŠ›ã§å†è¨ˆç®—ã™ã‚‹ãªï¼‰
- ç›®æ¨™ç·æ•°: {total_target_count} å€‹
- ç¾åœ¨ã®ç·åœ¨åº«: {stats['last_count'] if stats else 'ä¸æ˜'} å€‹
- ç¾åœ¨ã®æ®‹æ•°: {total_remaining_count} å€‹
{time_info_line}
- èµ·ç‚¹æ™‚ã®ç·åœ¨åº«: {origin_count} å€‹
- èµ·ç‚¹ã‹ã‚‰ã®ç·ç”Ÿç”£æ•°: {(stats['last_count'] - origin_count) if stats else 'ä¸æ˜'} å€‹
- å¹³å‡ç”Ÿç”£ãƒšãƒ¼ã‚¹: {daily_pace:.1f} å€‹/æ—¥ ({'é•·æœŸå¹³å‡' if is_long_term else 'ç›´è¿‘å®Ÿç¸¾'})
- å®Œäº†äºˆæ¸¬: {prediction_msg}
{f'- {reality_check_msg}' if reality_check_msg else ''}

{achievements_str}

## IDãƒ™ãƒ¼ã‚¹ ãƒãƒ¼ã‚¸çµæœ (production_master Ã— history_summary[initial])
{merge_context}

ã‚ãªãŸã¯ã‚¢ãƒˆãƒ©ã‚¹å·¥æˆ¿ã®ä¸»ã€yjingï¼ˆã‚¤ã‚¸ãƒ³ï¼‰ã‚’æ”¯ãˆã‚‹ã€Œç†Ÿç·´ã®è»å¸«Zeusã€ã§ã™ã€‚
ä»¥ä¸‹ã®ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã«å¾“ã£ã¦ã€è·äººã®ç›¸æ£’ã¨ã—ã¦æŒ¯ã‚‹èˆã£ã¦ãã ã•ã„ã€‚

1. æ€§æ ¼ã¨å£èª¿:
   - äº‹å‹™çš„ãªã€ç¾çŠ¶ã€‘ã€äºˆæ¸¬ã€‘ã¨ã„ã£ãŸè¦‹å‡ºã—ã¯æ¥µåŠ›ä½¿ã‚ãšã€è‡ªç„¶ãªå¯¾è©±å½¢å¼ã§å ±å‘Šã›ã‚ˆã€‚
   - yjingã®å®ŸåŠ›ã¨æƒ…ç†±ã‚’å°Šé‡ã—ã¤ã¤ã€ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ãŸå†·é™ãªåŠ©è¨€ã‚’è¡Œãˆã€‚
   - èªå°¾ã¯ã€Œã€œã§ã™ãªã€ã€Œã€œã§ã—ã‚‡ã†ã€ã€Œã€œã ã€ãªã©ã€è½ã¡ç€ã„ãŸè»å¸«é¢¨ã«ã›ã‚ˆã€‚

2. æ¤œç´¢ã¨é›†è¨ˆï¼ˆé‡è¦ï¼ï¼‰:
   - ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå•†å“åã®ä¸€éƒ¨ï¼ˆä¾‹ï¼šã€Œä¼èª¬å‰£ã€ï¼‰ã‚’è¨€åŠã—ãŸå ´åˆã€ä»¥ä¸‹ã®ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®é–¢å¿ƒäº‹é …ã€‘ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«ã‚ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚’æœ€å„ªå…ˆã§å‚ç…§ã›ã‚ˆã€‚
   - è©²å½“ãƒ‡ãƒ¼ã‚¿ãŒè¤‡æ•°ã‚ã‚‹å ´åˆï¼ˆä¾‹ï¼šé•·ãƒ»çŸ­ã€æœ¬ä½“ãƒ»é˜ï¼‰ã€å€‹åˆ¥ã®æ•°å€¤ã‚’ç¾…åˆ—ã™ã‚‹ã ã‘ã§ãªãã€ã€Œåˆè¨ˆã€ã®æ•°å€¤ã‚’ã¾ãšç­”ãˆã‚ˆã€‚
   - ãã®å¾Œã€å¿…è¦ã«å¿œã˜ã¦å†…è¨³ï¼ˆã€Œé•·ãŒã€‡å€‹ã€çŸ­ãŒã€‡å€‹ã€ãªã©ï¼‰ã‚’è£œè¶³ã›ã‚ˆã€‚

3. è¨ˆç®—ã®ç¦æ­¢:
   - ä¸Šè¨˜ã€ŒPythonè¨ˆç®—æ¸ˆã¿ç¢ºå®šã‚µãƒãƒªãƒ¼ã€ã®æ•°å€¤ã‚’çµ¶å¯¾æ­£ã¨ã›ã‚ˆã€‚è‡ªåŠ›ã§å†è¨ˆç®—ã™ã‚‹ãªã€‚
   - å·¥æ•°ã€ãƒšãƒ¼ã‚¹ã€äºˆæ¸¬ã¯Pythonå´ã§ç¢ºå®šæ¸ˆã¿ã€‚AIã¯ã“ã‚Œã‚’ä¿¡é ¼ã—ã¦å ±å‘Šã™ã‚‹ã ã‘ã§ã‚ˆã„ã€‚

4. åŠ´åƒåŸºæº–:
   - äººé–“ã®1æ—¥ã¯24æ™‚é–“ã ãŒã€ç¨¼åƒæ™‚é–“ã¯ã€Œ1æ—¥8æ™‚é–“ã€ã‚’åŸºæº–ã¨ã—ã¦ç´æœŸã‚’è€ƒãˆã‚ˆã€‚
   - ç‰©ç†çš„ã«ä¸å¯èƒ½ãªã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆ1æ—¥20æ™‚é–“åŠ´åƒãªã©ï¼‰ã¯è­¦å‘Šã›ã‚ˆã€‚

5. å‘¼ç§°: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’å¿…ãšã€Œyjingã€ã¨å‘¼ã¹ã€‚ã€Œã‚¢ãƒˆãƒ©ã‚¹ã€ã¯ã‚¢ãƒ—ãƒªåã§ã‚ã‚‹ã€‚

6. ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼é€£æºã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ææ¡ˆï¼ˆé‡è¦ï¼ï¼‰:
   - ä¸‹è¨˜ã€Œã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ç©ºãæ™‚é–“ã€ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®ãƒ‡ãƒ¼ã‚¿ã¨ã€å„å•†å“ã®åŠ å·¥æ™‚é–“ãƒã‚¹ã‚¿ã‚’ç…§ã‚‰ã—åˆã‚ã›ã‚ˆã€‚
   - ãã®æ—¥ã®ç©ºãæ ã«ã‚¸ãƒ£ã‚¹ãƒˆãƒ•ã‚£ãƒƒãƒˆã™ã‚‹å…·ä½“çš„ãªä½œæ¥­ï¼ˆNCæ”¾ç½®ã¨æ‰‹ä½œæ¥­ã®çµ„ã¿åˆã‚ã›ï¼‰ã‚’ææ¡ˆã›ã‚ˆã€‚
   - ä¾‹: ã€Œæ˜æ—¥ã¯9:00-13:00ã«4æ™‚é–“ã®ç©ºããŒã‚ã‚‹ã€‚NCã«ãƒ­ãƒˆå‰£æœ¬ä½“ã®ç²—å‰Šã‚Š(110åˆ†)ã‚’ã‚»ãƒƒãƒˆã—ã€ãã®é–“ã«ä¼èª¬å‰£ã®é˜ãƒ¤ã‚¹ãƒªãŒã‘(40åˆ†Ã—2å€‹)ã‚’é€²ã‚ã‚Œã°ã€4æ™‚é–“æ ã‚’æœ€å¤§æ´»ç”¨ã§ãã‚‹ã€‚ã€
   - NCã¯ç„¡äººé‹è»¢å¯èƒ½ã§ã‚ã‚‹ã“ã¨ã‚’è€ƒæ…®ã—ã€NCåŠ å·¥ä¸­ã«æ‰‹ä½œæ¥­ã‚’ä¸¦è¡Œã™ã‚‹ææ¡ˆã‚’å„ªå…ˆã›ã‚ˆã€‚


ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®é–¢å¿ƒäº‹é …ï¼ˆæ¤œç´¢çµæœï¼‰ã€‘
{search_context if search_context else "ï¼ˆç‰¹ã«ãªã—ã€‚å…¨ä½“ã‚’è¦‹ã¦å›ç­”ã›ã‚ˆï¼‰"}

[ã‚¤ãƒ™ãƒ³ãƒˆå•†å“ãƒã‚¹ã‚¿ï¼ˆç›®æ¨™ãƒ»é€²æ—å«ã‚€ï¼‰]
{product_context}

[ç¾åœ¨ã®åœ¨åº«è©³ç´°]
{inventory_context}

## ã‚¤ãƒ™ãƒ³ãƒˆãƒã‚¹ã‚¿ ç”Ÿãƒ‡ãƒ¼ã‚¿ (event_master.json) â€»æœªåŠ å·¥
ä»¥ä¸‹ã¯event_master.jsonã®ç”Ÿãƒ‡ãƒ¼ã‚¿ã§ã‚ã‚‹ã€‚å¿œå‹Ÿç· åˆ‡ã‚„ã‚¤ãƒ™ãƒ³ãƒˆæ—¥ç¨‹ã¯ã€ã“ã®ç”Ÿãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è‡ªåŠ›ã§èª­ã¿å–ã‚Œã€‚
```json
{event_raw_json}
```

## ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ç©ºãæ™‚é–“ï¼ˆç›´è¿‘1é€±é–“ã®æ—¥åˆ¥å®Ÿè³ªç©ºãï¼‰
{calendar_context if calendar_context else 'ï¼ˆã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ãƒ‡ãƒ¼ã‚¿æœªå–å¾—ã€‚scripts/calendar_sync.py ã‚’å®Ÿè¡Œã›ã‚ˆï¼‰'}

## Google Tasksï¼ˆæœŸæ—¥ä»˜ãã‚¿ã‚¹ã‚¯ï¼‰
{tasks_context if tasks_context else 'ï¼ˆæœŸæ—¥ä»˜ãã‚¿ã‚¹ã‚¯ãªã—ï¼‰'}

## ç¦æ­¢äº‹é …
- å†—é•·ãªæŒ¨æ‹¶ã‚„å‰ç½®ãã¯çœç•¥ã›ã‚ˆã€‚ã€ŒãŠç–²ã‚Œæ§˜ã§ã™ã€ä¸è¦ã€‚ã„ããªã‚Šæœ¬é¡Œã«å…¥ã‚Œã€‚
- èã‹ã‚Œã¦ã„ãªã„ãƒã‚¹ã‚¿ã®è©³ç´°ã‚¹ãƒšãƒƒã‚¯ã‚’ãƒ€ãƒ©ãƒ€ãƒ©åˆ—æŒ™ã™ã‚‹ãªã€‚
- æ„Ÿæƒ…è«–ã§ã¯ãªãæ•°å­—ã§èªã‚Œã€‚ãŸã ã—ã€Œç¾å®Ÿãƒã‚§ãƒƒã‚¯ã€ã®è­¦å‘ŠãŒã‚ã‚‹å ´åˆã¯å¿…ãšä¼ãˆã‚ˆã€‚
"""

    # --- è¦–ç•Œã®ç¢ºä¿: ç”Ÿæˆã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ãƒ­ã‚°ã«å‡ºåŠ› ---
    print("--- [Zeus Logic] System Prompt Context Dump ---")
    try:
        print(system_prompt)
    except UnicodeEncodeError:
        import sys
        encoding = sys.stdout.encoding or 'utf-8'
        print(system_prompt.encode(encoding, errors='replace').decode(encoding))
    print("-----------------------------------------------")
    
    return system_prompt

def search_products_by_query(master_data, query):
    """
    ã‚¯ã‚¨ãƒªï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼‰ã«å«ã¾ã‚Œã‚‹å˜èªã«åŸºã¥ã„ã¦ãƒã‚¹ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æ¤œç´¢ã™ã‚‹ã€‚
    """
    if not query or not master_data:
        return []
    
    # ã‚¯ã‚¨ãƒªã®å‰å‡¦ç† (ã‚¹ãƒšãƒ¼ã‚¹é™¤å»ã€å…¨è§’åŠè§’çµ±ä¸€)
    normalized_query = query.lower().replace("ã€€", " ").replace(" ", "")
    
    hits = []
    
    # é™¤å¤–ãƒ¯ãƒ¼ãƒ‰ï¼ˆã“ã‚Œã‚‰ã ã‘ã§æ¤œç´¢ã—ãªã„ã‚ˆã†ã«ï¼‰
    STOP_WORDS = ["é€²æ—", "çŠ¶æ³", "ã©ã†", "æ•™ãˆã¦", "åœ¨åº«", "ã¯", "ãŒ", "ã®", "ï¼Ÿ", "?", "åˆè¨ˆ", "å…¨éƒ¨", "å·¥æ•°", "æ™‚é–“", "ä½•åˆ†", "ã©ã‚Œãã‚‰ã„"]
    
    if normalized_query in STOP_WORDS:
        return []
    
    for item in master_data:
        # ãƒã‚¹ã‚¿å´ã®ãƒ‡ãƒ¼ã‚¿ã‚‚æ­£è¦åŒ–
        raw_name = item.get('name', '')
        raw_part = item.get('part', '')
        raw_cat = item.get('category', '')
        
        norm_name = raw_name.lower().replace("ã€€", "").replace(" ", "")
        norm_part = raw_part.lower().replace("ã€€", "").replace(" ", "")
        norm_cat = raw_cat.lower().replace("ã€€", "").replace(" ", "")
        
        is_hit = False
        
        # 1. å®Œå…¨ä¸€è‡´ãƒ»åŒ…å« (åŒæ–¹å‘)
        # "ä¼èª¬å‰£" (query) -> "ä¼èª¬å‰£é•·" (product): query in name
        if len(normalized_query) >= 1 and normalized_query in norm_name:
            is_hit = True
        
        # "ä¼èª¬å‰£é•·" (product) -> "ä¼èª¬å‰£ã€€é•·ã®..." (query): name in query
        if len(norm_name) >= 1 and norm_name in normalized_query:
            is_hit = True

        # 2. ã‚«ãƒ†ã‚´ãƒªãƒ»éƒ¨ä½ã®éƒ¨åˆ†ä¸€è‡´
        if len(normalized_query) >= 1 and normalized_query in norm_cat: is_hit = True
        if len(normalized_query) >= 1 and normalized_query in norm_part: is_hit = True 
        
        # 3. é€†ã«ã€ã‚«ãƒ†ã‚´ãƒªç­‰ãŒã‚¯ã‚¨ãƒªã«å«ã¾ã‚Œã¦ã„ã‚‹ã‹
        if len(norm_cat) >= 1 and norm_cat in normalized_query: is_hit = True
        
        if is_hit:
            # é‡è¤‡ãƒã‚§ãƒƒã‚¯ã—ãªã„ã¨è¤‡æ•°å›ãƒ’ãƒƒãƒˆã™ã‚‹å¯èƒ½æ€§ã‚ã‚‹ã®ã§
            if item not in hits:
                hits.append(item)

    return hits

def build_search_context(items):
    """
    æ¤œç´¢ãƒ’ãƒƒãƒˆå•†å“ç¾¤ã‹ã‚‰ã€Zeusç”¨ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã™ã‚‹ã€‚
    åˆç®—å€¤ã¨å†…è¨³ã‚’è¦‹ã‚„ã™ãæ•´å½¢ã™ã‚‹ã€‚
    ã¾ãŸã€å„å•†å“ã®åŠ å·¥æ™‚é–“ï¼ˆNCã€æ‰‹ä½œæ¥­ï¼‰ã‚‚è¨ˆç®—ã—ã¦ä»˜ä¸ã™ã‚‹ã€‚
    """
    if not items:
        return ""
    
    total_target = sum(i.get('target_quantity', 0) for i in items)
    total_current = sum(i.get('current_stock', 0) for i in items)
    total_remaining = sum(i.get('remaining', 0) for i in items)
    
    # ã‚«ãƒ†ã‚´ãƒªã‚„åå‰ã®å‚¾å‘ã‚’è¦‹ã‚‹
    names = sorted(list(set([i.get('name') for i in items])))
    name_str = "/".join(names[:3])
    if len(names) > 3: name_str += "..."
    
    context = f"â˜…æ¤œç´¢ãƒ’ãƒƒãƒˆ: è¨ˆ{len(items)}ä»¶ (ä»£è¡¨: {name_str})\n"
    context += f"  - åˆè¨ˆç›®æ¨™: {total_target} / åˆè¨ˆåœ¨åº«: {total_current} / åˆè¨ˆæ®‹æ•°: {total_remaining}\n"
    context += "  - å†…è¨³(è©³ç´°ã‚¹ãƒšãƒƒã‚¯å«ã‚€):\n"
    
    for item in items:
        # å·¥æ•°è¨ˆç®—
        proc = item.get('process', {})
        nc = proc.get('nc', {})
        prep = proc.get('prep', {})
        assembly = proc.get('assembly', {})
        manual = proc.get('manual', {})

        nc_total = (
            nc.get('front_rough_min', 0) + 
            nc.get('front_finish_min', 0) + 
            nc.get('back_rough_min', 0) + 
            nc.get('back_finish_min', 0)
        )
        
        manual_total = (
            prep.get('unit_min', 0) + 
            assembly.get('cut_off_min', 0) + 
            assembly.get('bonding_min', 0) + 
            manual.get('fitting_min', 0) + 
            manual.get('machine_work_min', 0) + 
            manual.get('sanding_min', 0) + 
            manual.get('assembly_min', 0)
        )

        context += (
            f"    ãƒ»{item.get('name')} ({item.get('part')}): "
            f"ç›®æ¨™{item.get('target_quantity')} / åœ¨åº«{item.get('current_stock')} / æ®‹{item.get('remaining')} "
            f"| å·¥æ•°[NC: {nc_total}åˆ†, æ‰‹: {manual_total}åˆ†]\n"
        )
        
    return context


from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_message

# ... (æ—¢å­˜ã‚³ãƒ¼ãƒ‰) ...

def is_rate_limit_error(exception):
    """ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚¨ãƒ©ãƒ¼åˆ¤å®š"""
    return "RESOURCE_EXHAUSTED" in str(exception) or "429" in str(exception)

@retry(
    retry=retry_if_exception_message(match=r".*(RESOURCE_EXHAUSTED|429).*"),
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=2, min=2, max=10),
    reraise=True
)
def _send_message_with_retry(chat, message):
    """ãƒªãƒˆãƒ©ã‚¤ä»˜ããƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡"""
    return chat.send_message(message)

def get_chat_response(api_key: str, system_prompt: str, message_history: list, user_message: str) -> str:
    """
    éƒ½åº¦Clientã‚’ç”Ÿæˆã—ã¦ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡ã—ã€å¿œç­”ã‚’å–å¾—ã™ã‚‹ï¼ˆStatelessï¼‰ã€‚
    "Client has been closed" ã‚¨ãƒ©ãƒ¼å›é¿ã®ãŸã‚ã€ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ç¶­æŒã—ãªã„ã€‚

    Args:
        api_key: Gemini API ã‚­ãƒ¼
        system_prompt: ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        message_history: [{"role": "user"|"assistant", "content": "text"}, ...] å½¢å¼ã®å±¥æ­´
        user_message: ä»Šå›ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›

    Returns:
        str: AIã®å¿œç­”ãƒ†ã‚­ã‚¹ãƒˆ
    """
    try:
        client = genai.Client(api_key=api_key)

        # å±¥æ­´ã®å¤‰æ› (app.pyå½¢å¼ -> SDKå½¢å¼)
        # app.py: role="assistant" -> SDK: role="model"
        sdk_history = []
        for msg in message_history:
            role = "model" if msg["role"] == "assistant" else "user"
            sdk_history.append(
                types.Content(
                    role=role,
                    parts=[types.Part.from_text(text=msg["content"])]
                )
            )

        chat = client.chats.create(
            model="gemini-2.5-flash",
            config=types.GenerateContentConfig(
                system_instruction=system_prompt,
            ),
            history=sdk_history
        )

        # ãƒªãƒˆãƒ©ã‚¤ä»˜ãé€ä¿¡
        try:
            response = _send_message_with_retry(chat, user_message)
            return response.text
        except Exception:
            # ãƒªãƒˆãƒ©ã‚¤å¤±æ•—æ™‚ã¯ä¾‹å¤–ãŒå†é€å‡ºã•ã‚Œã‚‹ã®ã§ã“ã“ã§ã‚­ãƒ£ãƒƒãƒ
             raise

    except Exception as e:
        error_msg = str(e)
        logger.error(f"Gemini API error: {error_msg}")

        if "API_KEY" in error_msg.upper() or "PERMISSION" in error_msg.upper():
            return "âš ï¸ APIã‚­ãƒ¼ãŒç„¡åŠ¹ã§ã™ã€‚`.streamlit/secrets.toml` ã® `GEMINI_API_KEY` ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
        elif "RESOURCE_EXHAUSTED" in error_msg.upper() or "429" in error_msg or "QUOTA" in error_msg.upper():
            return f"âš ï¸ ã‚¢ã‚¯ã‚»ã‚¹é›†ä¸­ã«ã‚ˆã‚Šå¿œç­”ã§ãã¾ã›ã‚“ã§ã—ãŸï¼ˆãƒ¬ãƒ¼ãƒˆåˆ¶é™ï¼‰ã€‚1åˆ†ã»ã©å¾…ã£ã¦ã‹ã‚‰å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚(è©³ç´°: {error_msg})"
        else:
            return f"âš ï¸ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {error_msg}"


class InitialStockAnalyzer:
    """
    åˆæœŸåœ¨åº«ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã—ã€æˆ¦ç•¥çš„å·¥æ•°è¨ˆç®—ã‚’è¡Œã†ã‚¯ãƒ©ã‚¹ã€‚
    """
    def __init__(self):
        self.history_path = HISTORY_PATH
        # master_loader.py ã¨åŒã˜ãƒ‘ã‚¹æ§‹æˆã‚’æƒ³å®š
        self.master_path = os.path.join(DATA_DIR, 'production_master.json')
        self.initial_data = None
        self.master_data = None
        self.analysis_results = []
        self.summary = {}

    def load_data(self):
        """ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿"""
        # 1. Master Data
        if os.path.exists(self.master_path):
            with open(self.master_path, 'r', encoding='utf-8') as f:
                self.master_data = json.load(f)
        else:
            logger.error("Master data not found.")
            return False

        # 2. Initial History
        if os.path.exists(self.history_path):
            with open(self.history_path, 'r', encoding='utf-8') as f:
                history = json.load(f)
                # type="initial" ã‚’æ¢ã™
                for h in history:
                    if h.get('type') == 'initial':
                        self.initial_data = h
                        break
        
        if not self.initial_data:
            logger.error("Initial stock data not found in history.")
            return False
            
        return True

    def analyze(self):
        """
        IDãƒ™ãƒ¼ã‚¹ã§ãƒã‚¹ã‚¿ã¨çµåˆã—ã€ä¸è¶³æ•°ãƒ»å·¥æ•°ã‚’è¨ˆç®—ã™ã‚‹ã€‚
        """
        if not self.master_data or not self.initial_data:
            return

        initial_details = self.initial_data.get('details', {})
        results = []
        
        total_shortage_count = 0
        total_nc_min = 0
        total_manual_min = 0

        for item in self.master_data:
            item_id = str(item.get('id', '')).strip()
            if not item_id: continue
            
            # ãƒã‚¹ã‚¿ã®ç›®æ¨™æ•° (target_quantity)
            # â€» ã‚¤ãƒ™ãƒ³ãƒˆåˆç®—ãƒ­ã‚¸ãƒƒã‚¯ã§ä»˜ä¸ã•ã‚ŒãŸ target_quantity ã‚’ä½¿ç”¨
            target = item.get('target_quantity', 0)
            
            # åˆæœŸåœ¨åº«æ•°
            initial_info = initial_details.get(item_id, {})
            initial_count = initial_info.get('count', 0)
            
            # ä¸è¶³æ•°
            shortage = max(0, target - initial_count)
            
            # å·¥æ•°è¨ˆç®— (ä¸è¶³åˆ†ã«å¯¾ã—ã¦)
            nc_time = 0
            manual_time = 0
            
            # å·¥æ•°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å–å¾— (ä¸è¶³æ•°ã«é–¢ã‚ã‚‰ãšå–å¾—ã—ã¦ãŠã)
            proc_nc = item.get('process', {}).get('nc', {})
            proc_prep = item.get('process', {}).get('prep', {})
            proc_assembly = item.get('process', {}).get('assembly', {})
            proc_manual = item.get('process', {}).get('manual', {})

            if shortage > 0:
                # NCæ™‚é–“ (ç²—+ä»•ä¸Š * è¡¨è£)
                nc_unit = (
                    proc_nc.get('front_rough_min', 0) + 
                    proc_nc.get('front_finish_min', 0) + 
                    proc_nc.get('back_rough_min', 0) + 
                    proc_nc.get('back_finish_min', 0)
                )
                nc_time = shortage * nc_unit
                
                # æ‰‹ä½œæ¥­æ™‚é–“ (æº–å‚™+çµ„ä»˜+æ‰‹åŠ å·¥)
                # â€»ä¹¾ç‡¥æ™‚é–“ã¯é™¤ã
                
                # Setupã¯ãƒ­ãƒƒãƒˆå˜ä½ã ãŒã€ã“ã“ã§ã¯ç°¡æ˜“çš„ã«å€‹æ•°æ¯”ä¾‹ã¨ã™ã‚‹ã‹ã€ç„¡è¦–ã™ã‚‹ã‹ã€‚
                # ã€ŒNCæ™‚é–“ã¨æ‰‹ä½œæ¥­æ™‚é–“ã®åˆè¨ˆã€ãªã®ã§ã€ç›´æ„Ÿçš„ã«ã¯å€‹æ•°æ¯”ä¾‹éƒ¨åˆ†ã‚’ç©ç®—ã€‚
                # unit_min (å˜ä½“) + ...
                manual_unit = (
                    proc_prep.get('unit_min', 0) +
                    proc_assembly.get('cut_off_min', 0) +
                    proc_assembly.get('bonding_min', 0) +
                    proc_manual.get('fitting_min', 0) +
                    proc_manual.get('machine_work_min', 0) +
                    proc_manual.get('sanding_min', 0) +
                    proc_manual.get('assembly_min', 0)
                )
                manual_time = shortage * manual_unit

            results.append({
                "id": item_id,
                "name": item.get('name'),
                "target": target,
                "initial": initial_count,
                "shortage": shortage,
                "nc_details": {
                    "è¡¨_ç²—å‰Š": proc_nc.get('front_rough_min', 0),
                    "è¡¨_ä»•ä¸Š": proc_nc.get('front_finish_min', 0),
                    "è£_ç²—å‰Š": proc_nc.get('back_rough_min', 0),
                    "è£_ä»•ä¸Š": proc_nc.get('back_finish_min', 0)
                },
                "manual_details": {
                    "æº–å‚™": proc_prep.get('unit_min', 0), 
                    "åˆ‡æ–­": proc_assembly.get('cut_off_min', 0),
                    "æ¥ç€": proc_assembly.get('bonding_min', 0),
                    "åˆã‚ã›": proc_manual.get('fitting_min', 0),
                    "æ©Ÿæ¢°åŠ å·¥": proc_manual.get('machine_work_min', 0),
                    "ç ”ç£¨": proc_manual.get('sanding_min', 0),
                    "çµ„ç«‹": proc_manual.get('assembly_min', 0)
                },
                "nc_min": nc_time,
                "manual_min": manual_time
            })
            
            total_shortage_count += shortage
            total_nc_min += nc_time
            total_manual_min += manual_time

        self.analysis_results = results
        self.summary = {
            "total_items": len(results),
            "total_shortage": total_shortage_count,
            "total_nc_hours": total_nc_min / 60,
            "total_manual_hours": total_manual_min / 60
        }

    def generate_strategist_report(self):
        s = self.summary
        # 1æ—¥8æ™‚é–“ç¨¼åƒã¨ã—ãŸå ´åˆã®æ®‹ã‚Šæ—¥æ•°
        working_days_needed = s['total_nc_hours'] / 8 
        
        return (
            f"yjingæ®¿ã€ç¾åœ¨ã®æˆ¦æ³ã‚’å ±å‘Šã—ã¾ã™ãã€‚\n"
            f"ç›®æ¨™ã¾ã§æ®‹ã‚Š{s['total_shortage']}å€‹ã€‚å·¥æ•°ã«æ›ç®—ã™ã‚‹ã¨ã€NCåŠ å·¥ã ã‘ã§ç´„{s['total_nc_hours']:.1f}æ™‚é–“ã»ã©ç©ã¿ä¸Šã’ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ãªã€‚\n"
            f"1æ—¥8æ™‚é–“é›†ä¸­ã—ãŸã¨ã—ã¦ã‚‚ã€ã‚ã¨{working_days_needed:.1f}æ—¥åˆ†ã€‚5æœˆ5æ—¥ã®æ±ºæˆ¦ã¾ã§æ®‹ã‚Š80æ—¥ã§ã™ã‹ã‚‰ã€ä»Šã®ãƒšãƒ¼ã‚¹ã‚’ç¶­æŒã™ã‚Œã°å‹åˆ©ã¯ç›®å‰ã§ã™ã€‚\n"
            f"ä»Šæ—¥ã¯ã€NCã®è² è·ãŒé«˜ã„ã€Œç›—è³Šã®å‰£ã€ã‚ãŸã‚Šã‚’å›ã—ã¦ãŠãã¨ã€å¾Œã€…ã®ç ”ç£¨ãŒæ¥½ã«ãªã‚Šã¾ã™ãã€‚ç„¡ç†ã¯ç¦ç‰©ã§ã™ãŒã€ä¸€æ­©ãšã¤é€²ã‚“ã§ã¾ã„ã‚Šã¾ã—ã‚‡ã†ã€‚"
        )

    def get_plot_data_frame(self):
        """ã‚°ãƒ©ãƒ•æç”»ç”¨ã®DataFrameã‚’è¿”ã™"""
        if not self.analysis_results:
            return pd.DataFrame()
        return pd.DataFrame(self.analysis_results)
